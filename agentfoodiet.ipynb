{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"c88f5b7c-6fc6-46cb-bac9-dc73474ebd16","_cell_guid":"118e5a2b-5d29-4b4a-ae99-3f9c10470775","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-05T14:49:11.960906Z","iopub.execute_input":"2025-04-05T14:49:11.961244Z","iopub.status.idle":"2025-04-05T14:49:13.013349Z","shell.execute_reply.started":"2025-04-05T14:49:11.961212Z","shell.execute_reply":"2025-04-05T14:49:13.012253Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Food Recommendation AI Agent\n\n## Project Structure\n\n- `food-recommendation-ai/`\n  - `data/`\n    - `raw/` (Raw datasets)\n    - `processed/` (Processed datasets)\n  - `models/` (Trained models)\n  - `notebooks/` (Kaggle Notebooks)\n  - `README.md` (Project description and instructions)\n  - `src/` (Python scripts for data processing and model training)","metadata":{}},{"cell_type":"markdown","source":"# Food Recommendation AI Agent\n\n## Introduction\n### Problem Statement\nThe objective of this project is to develop an AI agent that can recommend food items based on user preferences, dietary restrictions, and other contextual factors such as time of day and weather. This can help users discover new recipes and make informed decisions about their meals.\n\n### Objectives\n- Personalized food recommendations based on user preferences.\n- Filtering options for dietary restrictions (e.g., vegetarian, vegan, gluten-free).\n- Contextual recommendations (e.g., breakfast, lunch, dinner, snacks).\n- Integration with a database of recipes or restaurants.","metadata":{}},{"cell_type":"markdown","source":"## Data Collection\n### Datasets\n- **User Preferences**: Collect data on user preferences through surveys or forms.\n- **Dietary Restrictions**: Collect data on common dietary restrictions.\n- **Recipe Database**: Use publicly available datasets like the [Recipe1M](https://sites.google.com/view/recipe1m) dataset or scrape data from websites like Allrecipes.\n- **Restaurant Data**: Use APIs like Yelp or Google Places for restaurant recommendations.\n\n### Data Sources\n- [Recipe1M Dataset](https://sites.google.com/view/recipe1m) [^2^]\n- [Zomato Restaurants Data](https://www.kaggle.com/datasets/zomato/zomato-restaurants-data) [^2^]","metadata":{}},{"cell_type":"markdown","source":"## Data Preprocessing\n### Steps\n1. **Loading Data**: Load the datasets into Pandas DataFrames.\n2. **Cleaning**: Remove duplicates, handle missing values, and standardize data formats.\n3. **Feature Engineering**: Create features that will be useful for recommendation, such as cuisine type, main ingredients, cooking time, etc.\n4. **Normalization**: Normalize numerical features if necessary.\n\n### Code\n```python\nimport pandas as pd\n\n# Load the dataset\ndata = pd.read_csv('data/raw/recipes.csv')\n\n# Handle missing values\ndata.fillna(method='ffill', inplace=True)\n\n# Feature engineering\ndata['cuisine_type'] = data['cuisine'].apply(lambda x: x.split()[0])\n\n# Normalize numerical features\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndata[['cooking_time']] = scaler.fit_transform(data[['cooking_time']])","metadata":{}},{"cell_type":"markdown","source":"#### 4. Model Selection\nDescribe the models you will use for recommendations.\n\n```markdown\n## Model Selection\n### Models\n1. **Collaborative Filtering**: Use user-item interaction data to recommend food items similar to what other users with similar preferences like.\n2. **Content-Based Filtering**: Use item features (e.g., ingredients, cuisine type) to recommend items similar to what the user has liked in the past.\n3. **Hybrid Approach**: Combine collaborative and content-based filtering for better recommendations.\n\n### Libraries\n- [Surprise](https://surprise.readthedocs.io/en/stable/) for collaborative filtering\n- [Scikit-learn](https://scikit-learn.org/stable/) for content-based filtering","metadata":{}},{"cell_type":"markdown","source":"## Model Training\n### Steps\n1. **Split Data**: Split your data into training and testing sets.\n2. **Train Models**: Train your chosen models on the training set.\n3. **Evaluate Models**: Use metrics like precision, recall, F1-score, and RMSE to evaluate your models on the test set.\n\n### Code\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# Split data\ntrain_data, test_data = train_test_split(data, test_size=0.2)\n\n# Train a content-based filtering model\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ntfidf = TfidfVectorizer(stop_words='english')\ntfidf_matrix = tfidf.fit_transform(train_data['ingredients'])\n\ncosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n\n# Evaluate the model\n# Example: Calculate precision, recall, and F1-score\nprecision = precision_score(test_data['label'], predictions)\nrecall = recall_score(test_data['label'], predictions)\nf1 = f1_score(test_data['label'], predictions)\n\nprint(f'Precision: {precision}, Recall: {recall}, F1 Score: {f1}')","metadata":{}},{"cell_type":"markdown","source":"\n#### 6. Recommendation Engine\nDescribe how you will build and test the recommendation engine.\n\n```markdown\n## Recommendation Engine\n### Steps\n1. **User Input Interface**: Create a simple interface where users can input their preferences and restrictions.\n2. **Recommendation Logic**: Implement the logic to generate recommendations based on user input.\n3. **Output**: Display the recommended food items or recipes.\n\n### Code\n```python\ndef get_recommendations(user_input):\n    # Example: Use cosine similarity to find similar recipes\n    idx = indices[user_input]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:11]\n    recipe_indices = [i[0] for i in sim_scores]\n    \n    return data['title'].iloc[recipe_indices]\n\n# Example user input\nuser_input = 'Italian'\nrecommendations = get_recommendations(user_input)\nprint(recommendations)","metadata":{}},{"cell_type":"markdown","source":"\n#### 7. Testing and Validation\nExplain how you will test and validate your recommendation system.\n\n```markdown\n## Testing and Validation\n### Steps\n1. **User Testing**: Test the recommendation system with a few users to gather feedback.\n2. **Iterate**: Make improvements based on user feedback and re-evaluate the model.\n\n### Code\n```python\n# Example: Collect user feedback\nuser_feedback = {'recipe1': 'like', 'recipe2': 'dislike'}\n# Use feedback to improve the model","metadata":{}},{"cell_type":"markdown","source":"\n#### 8. Conclusion\nSummarize your project and suggest future work.\n\n```markdown\n## Conclusion\n### Summary\nThis project developed a food recommendation AI agent that provides personalized food recommendations based on user preferences and dietary restrictions. The system uses a hybrid approach combining collaborative and content-based filtering to generate accurate recommendations.\n\n### Future Work\n- Integrate more contextual factors like weather and time of day.\n- Expand the dataset to include more recipes and restaurants.\n- Improve the user interface for better user experience.","metadata":{}},{"cell_type":"markdown","source":"## References\n- [Recipe1M Dataset](https://sites.google.com/view/recipe1m) [^2^]\n- [Zomato Restaurants Data](https://www.kaggle.com/datasets/zomato/zomato-restaurants-data) [^2^]","metadata":{}}]}